{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 2--ShapeAI_Pratyusha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1w85Tc78npCpwSt0geZ2UdMQoSeMI6qpp",
      "authorship_tag": "ABX9TyPnBX1uimlObtmm5jjDa2vN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratyusha-code/Flower-Classification/blob/main/Project_2_ShapeAI_Pratyusha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVr_lnEETap-"
      },
      "source": [
        "# **PRATYUSHA MITRA**\n",
        "\n",
        "**PROJECT 2 : FLOWER CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ewAMtTW7V5-"
      },
      "source": [
        "**Import Headers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3AHwHkD0MJa"
      },
      "source": [
        "General Headers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UON2uQnNAuDz"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knrDk5Y_0RaV"
      },
      "source": [
        "PyTorch based Headers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iqW-Yjhk5OL"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch \n",
        "from torch import nn\n",
        "from torch.nn import functional as Fp ins\n",
        "from torch import optim\n",
        "import torchvision.models as models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PoEZpF_0WQk"
      },
      "source": [
        "**SETTING UP THE DEVICE FOR GPU COMPUTATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsySifKhCTRw"
      },
      "source": [
        "1. Cuda : For faster computation using GPU\n",
        "2. CPU : For normal computations\n",
        "3. nvidia-smi : To check the GPU unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkrsI3rEl4A7",
        "outputId": "3eb5953e-f980-49f9-804d-79ad57ba2560"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print('use_cuda: {}'.format(use_cuda))\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device to be used : \",device)\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use_cuda: True\n",
            "Device to be used :  cuda\n",
            "Sun Oct 24 09:27:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4D25A8gDK4r"
      },
      "source": [
        "**Setting up Data Path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nmue6Bn8R4l"
      },
      "source": [
        "def read_data(data_path):\n",
        "\n",
        "    labels = os.listdir(data_path)\n",
        "    data = []\n",
        "    X = []\n",
        "    Y = []\n",
        "    for l in labels:\n",
        "        for img_addr in os.listdir(os.path.join(data_path,l)):\n",
        "            X.append(os.path.join(data_path, l, img_addr))\n",
        "            Y.append(l)\n",
        "\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(Y)\n",
        "    Y = le.transform(Y)\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        data.append((X[i],Y[i]))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Tp6MXTIpWG"
      },
      "source": [
        "data = read_data(\"/content/drive/MyDrive/flowers\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbxSJqSd9lpn"
      },
      "source": [
        "**DATA GENERATOR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLBq5_zjkd9u"
      },
      "source": [
        "class DataGenerator(Dataset):\n",
        "\t\n",
        "    def __init__(self, image_list):\n",
        "        self.files = image_list\n",
        "        \n",
        "\n",
        "    #NUMBER OF FILES IN THE DATASET\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "        \n",
        "\n",
        "    #GETTING SINGLE PAIR OF DATA\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        img = cv2.imread(self.files[idx][0])\n",
        "        img = cv2.resize(img,(224,224))\n",
        "        img = img * 1./255.\n",
        "        img = (img - 0.5) + 0.5\n",
        "        label = self.files[idx][1]\n",
        "        return torch.FloatTensor(img).permute(2,0,1), torch.tensor(label)\n",
        "\t\t\n",
        "\t\n",
        "def load_data(data, batch_size=32, num_workers=10, shuffle=True):\n",
        "\n",
        "    dataset = DataGenerator(data)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
        "\n",
        "    return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAYmhm0RyMJy"
      },
      "source": [
        "class Flower_Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flower_Classifier, self).__init__()\n",
        "\n",
        "        model_ft = models.vgg16(pretrained=True)\n",
        "        model_ft.classifier = model_ft.classifier[:-1]\n",
        "        model_ft.requires_grad_ = False\n",
        "        self.flower_decode = nn.Sequential(model_ft,\n",
        "                                           nn.Linear(4096,32),\n",
        "                                           nn.Linear(32,16),\n",
        "                                           nn.Linear(16,5))\n",
        "        \n",
        "    def forward(self, flower_image):\n",
        "        decoded_vector = self.flower_decode(flower_image)\n",
        "        return decoded_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wg7mYyzll_A"
      },
      "source": [
        "**MODULE 3 : Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzpzfp66WdvW"
      },
      "source": [
        "**SAVE CHECKPOINT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx72WwzNWhC7"
      },
      "source": [
        "def save_ckp(checkpoint, checkpoint_path):\n",
        "    torch.save(checkpoint, checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nsJKr9QWhrT"
      },
      "source": [
        "**LOAD CHECKPOINT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYwO7XeWWmOJ"
      },
      "source": [
        "def load_ckp(checkpoint_path, model, model_opt):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model_opt.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, model_opt, checkpoint['epoch']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sncpj_TLGqAO"
      },
      "source": [
        "**TRAIN EPOCH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFbFHbMuBz6S"
      },
      "source": [
        "def train_epoch(train_loader, model, optimizer, epoch):\n",
        "\n",
        "    progress_bar = tqdm(enumerate(train_loader))\n",
        "    total_loss = 0.0\n",
        "    for step, (img, label) in progress_bar:\n",
        "\n",
        "        model = model.to(device)\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        model.train()\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred_label = model.forward(img)\n",
        "        ce = nn.CrossEntropyLoss()\n",
        "        ce_loss = ce(pred_label,label)\n",
        "        ce_loss.backward()\n",
        "        optimizer.step()\n",
        "        progress_bar.set_description(\"Epoch : {} Training Loss : {} \".format(epoch, ce_loss))\n",
        "\n",
        "    return model, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCkZ-xesfRbj"
      },
      "source": [
        "def val_epoch(val_loader, model, optimizer, epoch):\n",
        "\n",
        "    progress_bar = tqdm(enumerate(val_loader))\n",
        "    total_loss = 0.0\n",
        "    for step, (img, label) in progress_bar:\n",
        "\n",
        "        model = model.to(device)\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        model.eval()\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        #optimizer.zero_grad()\n",
        "        pred_label = model.forward(img)\n",
        "        ce = nn.CrossEntropyLoss()\n",
        "        ce_loss = ce(pred_label,label)\n",
        "        #ce_loss.backward()\n",
        "        #optimizer.step()\n",
        "        progress_bar.set_description(\"Epoch : {} Validation Loss : {} \".format(epoch-1, ce_loss))\n",
        "\n",
        "    return model, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u-J4RpFjVrO"
      },
      "source": [
        "def test_epoch(test_loader, model, optimizer, epoch):\n",
        "\n",
        "    progress_bar = tqdm(enumerate(test_loader))\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    for step, (img, label) in progress_bar:\n",
        "\n",
        "        model = model.to(device)\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        model.eval()\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        pred_label = model.forward(img)\n",
        "        \n",
        "        correct += (label == pred_label.argmax(1)).sum()\n",
        "    print(\"Accuracy: {}\".format(correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t3jslWRG6sR"
      },
      "source": [
        "**Code to control the Train, Test & Val**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOj06fhkBfON"
      },
      "source": [
        "def train_val_test(train_loader, val_loader, test_loader, model, optimizer, n_epoch, resume):\n",
        "\n",
        "    #PATH TO SAVE THE CHECKPOINT\n",
        "    checkpoint_path = \"/ssd_scratch/pratyusha_m/checkpoints/checkpoint.pt\"\n",
        "\n",
        "    epoch = 0\n",
        "    #IF TRAINING IS TO RESUMED FROM A CERTAIN CHECKPOINT\n",
        "    if resume:\n",
        "        model, optimizer, epoch = load_ckp(\n",
        "            checkpoint_path, model, optimizer)\n",
        "\n",
        "    while 1:\n",
        "        model, optimizer = train_epoch(train_loader, model, optimizer, epoch)\n",
        "        \n",
        "        #CHECKPOINT CREATION\n",
        "        checkpoint = {'epoch': epoch+1, 'state_dict': model.state_dict(),\n",
        "                      'optimizer': optimizer.state_dict()}\n",
        "        \n",
        "        #CHECKPOINT SAVING\n",
        "        save_ckp(checkpoint, checkpoint_path)\n",
        "        print(\"Checkpoint Saved\")\n",
        "\n",
        "        #CHECKPOINT LOADING\n",
        "        #model, optimizer, epoch = load_ckp(checkpoint_path, model, optimizer)\n",
        "        #print(\"Checkpoint Loaded\")\n",
        "        with torch.no_grad():\n",
        "            val_epoch(val_loader, model, optimizer, epoch)\n",
        "            test_epoch(test_loader, model, optimizer, epoch)\n",
        "        epoch+=1\t "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjZ7fZkUWOO4"
      },
      "source": [
        "**MAIN FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d80vuRX7nDFM"
      },
      "source": [
        "def main():\n",
        "\n",
        "    data_path = \"/home/projects/Flower_Classification/flowers\"\n",
        "    data  = read_data(data_path)\n",
        "    random.shuffle(data)\n",
        "    train_data = data[:int(0.6*len(data))]\n",
        "    validation_data = data[len(train_data):len(train_data) + int(0.2*len(data))]\n",
        "    test_data = data[len(train_data)+len(validation_data):]\n",
        "    print(\"Total Number of samples : \",len(data))\n",
        "    print(\"Train : {}, Validation : {}, Test : {}\".format(len(train_data), len(validation_data), len(test_data)))\n",
        "\n",
        "\n",
        "    #CREATING THE TRAIN LOADER\n",
        "    train_loader = load_data(train_data, batch_size=32, num_workers=2, shuffle=True)\n",
        "    \n",
        "    #CREATING THE VALIDATION LOADER\n",
        "    val_loader = load_data(validation_data, batch_size=32, num_workers=2, shuffle=True)\n",
        "    \n",
        "    #CREATING THE TEST LOADER\n",
        "    test_loader = load_data(test_data, batch_size=32, num_workers=2, shuffle=True)\n",
        "\n",
        "    #CALLING THE MODEL\n",
        "    model = Flower_Classifier()\n",
        "    \n",
        "    #UPLOADING THE MODEL TO DEVICE\n",
        "    model = model.to(device)\n",
        "\n",
        "    #DEFINING THE OPTIMIZER\n",
        "    optimizer = optim.Adam(\n",
        "        [p for p in model.parameters() if p.requires_grad], lr=0.01)\n",
        "    \n",
        "    n_epoch = 100\n",
        "    \n",
        "    #INDICATOR VARIABLE TO RESUME TRAINING OR START AFRESH\n",
        "    resume = False\n",
        "    train_val_test(train_loader, val_loader, test_loader,model, optimizer, n_epoch, resume)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwxERyJxWTFz"
      },
      "source": [
        "**CALLING THE MAIN FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8TmBvZEDTp6"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIw4sAM2QZOa"
      },
      "source": [
        "**To Note : This Code we executed in GPU in Terminal in my Desktop. Thease are the training log files. Running in Colab GPU was slow.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egz58M7bQRER"
      },
      "source": [
        "use_cuda: True\n",
        "Device to be used :  cuda\n",
        "Total Number of samples :  4327\n",
        "Train : 2596, Validation : 865, Test : 866\n",
        "Epoch : 0 Training Loss : 0.18956269323825836 : : 82it [00:16,  4.97it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : -1 Validation Loss : 0.0015585192013531923 : : 28it [00:01, 14.70it/s]\n",
        "28it [00:01, 15.29it/s]\n",
        "Accuracy: 0.8083140850067139\n",
        "Epoch : 1 Training Loss : 1.6656051874160767 : : 82it [00:16,  4.96it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 0 Validation Loss : 0.004584990907460451 : : 28it [00:01, 15.11it/s]\n",
        "28it [00:01, 16.08it/s]\n",
        "Accuracy: 0.8660507798194885\n",
        "Epoch : 2 Training Loss : 0.18563959002494812 : : 82it [00:16,  4.94it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 1 Validation Loss : 3.083498001098633 : : 28it [00:01, 15.03it/s]  \n",
        "28it [00:01, 16.17it/s]\n",
        "Accuracy: 0.8521940112113953\n",
        "Epoch : 3 Training Loss : 1.5795180843269918e-06 : : 82it [00:16,  4.93it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 2 Validation Loss : 1.1920928244535389e-07 : : 28it [00:01, 15.15it/s]\n",
        "28it [00:01, 15.83it/s]\n",
        "Accuracy: 0.8799076080322266\n",
        "Epoch : 4 Training Loss : 1.1065523624420166 : : 82it [00:16,  4.93it/s]   \n",
        "Checkpoint Saved\n",
        "Epoch : 3 Validation Loss : 1.1552094221115112 : : 28it [00:01, 15.11it/s] \n",
        "28it [00:01, 16.04it/s]\n",
        "Accuracy: 0.7586604952812195\n",
        "Epoch : 5 Training Loss : 0.00019396046991460025 : : 82it [00:16,  4.93it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 4 Validation Loss : 0.002970451721921563 : : 28it [00:01, 15.11it/s]\n",
        "28it [00:01, 16.01it/s]\n",
        "Accuracy: 0.8648960590362549\n",
        "Epoch : 6 Training Loss : 0.0038618925027549267 : : 82it [00:16,  4.92it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 5 Validation Loss : 0.0 : : 28it [00:01, 15.12it/s]                \n",
        "28it [00:01, 16.00it/s]\n",
        "Accuracy: 0.8891454935073853\n",
        "Epoch : 7 Training Loss : 0.04477012902498245 : : 82it [00:16,  4.93it/s]  \n",
        "Checkpoint Saved\n",
        "Epoch : 6 Validation Loss : 0.0 : : 28it [00:01, 15.13it/s]                \n",
        "28it [00:01, 15.99it/s]\n",
        "Accuracy: 0.8937644362449646\n",
        "Epoch : 8 Training Loss : 0.004453101195394993 : : 82it [00:16,  4.92it/s]  \n",
        "Checkpoint Saved\n",
        "Epoch : 7 Validation Loss : 0.0 : : 28it [00:01, 15.13it/s]               \n",
        "28it [00:01, 16.00it/s]\n",
        "Accuracy: 0.8279445767402649\n",
        "Epoch : 9 Training Loss : 2.1457581169670448e-06 : : 82it [00:16,  4.92it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 8 Validation Loss : 6.183901786804199 : : 28it [00:01, 15.07it/s]  \n",
        "28it [00:01, 15.98it/s]\n",
        "Accuracy: 0.8833718299865723\n",
        "Epoch : 10 Training Loss : 0.01083929743617773 : : 82it [00:16,  4.93it/s]   \n",
        "Checkpoint Saved\n",
        "Epoch : 9 Validation Loss : 0.0 : : 28it [00:01, 15.12it/s]                \n",
        "28it [00:01, 16.17it/s]\n",
        "Accuracy: 0.8568129539489746\n",
        "Epoch : 11 Training Loss : 0.000218683693674393 : : 82it [00:16,  4.92it/s]  \n",
        "Checkpoint Saved\n",
        "Epoch : 10 Validation Loss : 0.00017998983094003052 : : 28it [00:01, 15.05it/s]\n",
        "28it [00:01, 16.10it/s]\n",
        "Accuracy: 0.8718245029449463\n",
        "Epoch : 12 Training Loss : 2.8459604436648078e-05 : : 82it [00:16,  4.92it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 11 Validation Loss : 0.0 : : 28it [00:01, 15.05it/s]                 \n",
        "28it [00:01, 16.02it/s]\n",
        "Accuracy: 0.8625866174697876\n",
        "Epoch : 13 Training Loss : 0.00902835838496685 : : 82it [00:16,  4.93it/s]   \n",
        "Checkpoint Saved\n",
        "Epoch : 12 Validation Loss : 0.0 : : 28it [00:01, 15.12it/s]                \n",
        "28it [00:01, 16.00it/s]\n",
        "Accuracy: 0.8556581735610962\n",
        "Epoch : 14 Training Loss : 0.00013321341248229146 : : 82it [00:16,  4.92it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 13 Validation Loss : 0.0 : : 28it [00:01, 15.08it/s]                 \n",
        "28it [00:01, 16.00it/s]\n",
        "Accuracy: 0.8879907727241516\n",
        "Epoch : 15 Training Loss : 1.072882469088654e-06 : : 82it [00:16,  4.92it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 14 Validation Loss : 1.1920928244535389e-07 : : 28it [00:01, 15.02it/s]\n",
        "28it [00:01, 15.92it/s]\n",
        "Accuracy: 0.8521940112113953\n",
        "Epoch : 16 Training Loss : 0.18984085321426392 : : 82it [00:16,  4.92it/s]   \n",
        "Checkpoint Saved\n",
        "Epoch : 15 Validation Loss : 2.244469404220581 : : 28it [00:01, 15.03it/s]  \n",
        "28it [00:01, 16.18it/s]\n",
        "Accuracy: 0.8637413382530212\n",
        "Epoch : 17 Training Loss : 6.824669981142506e-06 : : 82it [00:16,  4.93it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 16 Validation Loss : 0.0 : : 28it [00:01, 15.13it/s]                \n",
        "28it [00:01, 16.02it/s]\n",
        "Accuracy: 0.8891454935073853\n",
        "Epoch : 18 Training Loss : 2.139746538887266e-05 : : 82it [00:16,  4.92it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 17 Validation Loss : 0.0 : : 28it [00:01, 15.09it/s]                 \n",
        "28it [00:01, 16.23it/s]\n",
        "Accuracy: 0.8660507798194885\n",
        "Epoch : 19 Training Loss : 2.849020529538393e-05 : : 82it [00:16,  4.93it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 18 Validation Loss : 1.5798382759094238 : : 28it [00:01, 14.89it/s] \n",
        "28it [00:01, 16.06it/s]\n",
        "Accuracy: 0.8660507798194885\n",
        "Epoch : 20 Training Loss : 2.890810264943866e-06 : : 82it [00:16,  4.92it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 19 Validation Loss : 4.6132929128361866e-05 : : 28it [00:01, 15.12it/s]\n",
        "28it [00:01, 16.07it/s]\n",
        "Accuracy: 0.8891454935073853\n",
        "Epoch : 21 Training Loss : 1.9519775378284976e-05 : : 82it [00:16,  4.92it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 20 Validation Loss : 0.0 : : 28it [00:01, 15.06it/s]                \n",
        "28it [00:01, 16.07it/s]\n",
        "Accuracy: 0.8787528872489929\n",
        "Epoch : 22 Training Loss : 0.01711004227399826 : : 82it [00:16,  4.92it/s]   \n",
        "Checkpoint Saved\n",
        "Epoch : 21 Validation Loss : 0.0 : : 28it [00:01, 15.12it/s]               \n",
        "28it [00:01, 16.01it/s]\n",
        "Accuracy: 0.8233256340026855\n",
        "Epoch : 23 Training Loss : 0.003298721509054303 : : 82it [00:16,  4.92it/s] \n",
        "Checkpoint Saved\n",
        "Epoch : 22 Validation Loss : 1.1920928244535389e-07 : : 28it [00:01, 15.06it/s]\n",
        "28it [00:01, 16.03it/s]\n",
        "Accuracy: 0.8729792237281799\n",
        "Epoch : 24 Training Loss : 0.014698987826704979 : : 82it [00:16,  4.93it/s]  \n",
        "Checkpoint Saved\n",
        "Epoch : 23 Validation Loss : 0.00011991735664196312 : : 28it [00:01, 15.10it/s]\n",
        "28it [00:01, 16.21it/s]\n",
        "Accuracy: 0.8545034527778625\n",
        "Epoch : 25 Training Loss : 3.3378389616700588e-06 : : 82it [00:16,  4.93it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 24 Validation Loss : 0.0 : : 28it [00:01, 15.00it/s]                \n",
        "28it [00:01, 15.96it/s]\n",
        "Accuracy: 0.9053117632865906\n",
        "Epoch : 26 Training Loss : 2.6135952793993056e-05 : : 82it [00:16,  4.92it/s]\n",
        "Checkpoint Saved\n",
        "Epoch : 25 Validation Loss : 0.0 : : 28it [00:01, 15.13it/s]                 \n",
        "28it [00:01, 15.95it/s]\n",
        "Accuracy: 0.9110854268074036\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa_Ak4dKQSNX"
      },
      "source": [
        "# **Final Accuracy Reported after 25th Epoch on the Test Set is : 91.11%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flQ-iFHdWTBO"
      },
      "source": [
        "**Here we are submittng a txt file which have the google drive link for our pickle model.**"
      ]
    }
  ]
}